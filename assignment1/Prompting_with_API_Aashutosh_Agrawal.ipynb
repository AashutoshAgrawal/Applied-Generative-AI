{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/AashutoshAgrawal/Applied-Generative-AI/blob/main/Prompting_with_API_Aashutosh_Agrawal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["# Applied Generative AI\nInstructor: Prof. Dehghani\nWelcome to the Applied Generative AI course. In this course, we will explore the foundations and applications of Generative AI using tools like OpenAI's API. By the end of this session, you will be able to:\n\nüü¢ Understand how to set up and connect to OpenAI's API.\nüåü Learn about the roles (System, Assistant, User) in prompt design.\n‚ú® Generate text, images, and vector embeddings programmatically.\nüîß Explore fine-tuning to customize AI models for specific tasks.\nLet's get started with setting up the OpenAI API!"],"metadata":{"id":"3S5eQNmwPUH8"}},{"cell_type":"code","source":["# Install the OpenAI Python SDK\n# This library allows us to interact with OpenAI's API for text, images, and embeddings.\n!pip install openai==0.28"],"metadata":{"id":"WNdB6dNqWG7L","outputId":"8667d47b-b77a-433f-d077-d9d1a4448e20","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai==0.28\n  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.13.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2026.1.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.22.0)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\nDownloading openai-0.28.0-py3-none-any.whl (76 kB)\n\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: openai\n  Attempting uninstall: openai\n    Found existing installation: openai 2.14.0\n    Uninstalling openai-2.14.0:\n      Successfully uninstalled openai-2.14.0\nSuccessfully installed openai-0.28.0\n"]}]},{"cell_type":"code","source":["from google.colab import userdata\nimport openai\n\n# Retrieve the key from Colab secrets\nopenai.api_key = userdata.get(\"OPENAI_API_KEY\")\n\n# Confirm the key was loaded (for debugging only; don't print your real key in shared notebooks!)\nprint(\"Key loaded:\", \"Yes\" if openai.api_key else \"No\")\n"],"metadata":{"id":"IkCBK7FpWJ4e","outputId":"54df3de0-c7dd-42bb-9f7d-b12cb5970fab","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Key loaded: Yes\n"]}]},{"cell_type":"markdown","source":["üéØ Prompt Playground: Understanding Roles\nIn OpenAI's API, you interact with the model using roles, which define the flow of the conversation:\n\n‚û°Ô∏è System: Sets the behavior and tone of the assistant (e.g., \"You are a cheerful assistant.\").\n‚û°Ô∏è User: Represents the input or question from the user (e.g., \"What is AI?\").\n‚û°Ô∏è Assistant: Automatically generated responses based on the system and user inputs.\nüí° Why Roles Matter: Roles help control the assistant's personality and the quality of responses. For example:\n\nA system message like \"You are a strict teacher\" makes the assistant respond more formally.\nA system message like \"You are a friendly chatbot\" leads to casual responses.\nLet's see how these roles work in the next cell!\n\n## Example 1: Without Assistant Role"],"metadata":{"id":"Rtir4dZMPrc3"}},{"cell_type":"code","source":["import openai\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n    ]\n)\n\nprint(response['choices'][0]['message']['content'])\n"],"metadata":{"id":"YXvUTgLCWq4u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Example 2: With Assistant Role"],"metadata":{"id":"ytKbu3esTO5N"}},{"cell_type":"code","source":["# Demonstrating roles in OpenAI's API with the assistant role\n\n# Define the conversation including a predefined assistant response\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a math tutor who explains problems step by step.\"},  # System role sets the behavior\n    {\"role\": \"user\", \"content\": \"Solve for x: 2x + 5 = 15\"},  # User question\n    {\"role\": \"assistant\", \"content\": \"To solve for x: \\n1. Subtract 5 from both sides: 2x = 10\\n2. Divide both sides by 2: x = 5\"}  # Predefined assistant response\n]\n\n# Send the conversation to the API\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-4\",  # Use the chosen model\n    messages=messages  # Pass the conversation\n)\n\n# Print the assistant's response\nprint(\"Assistant's Response:\", response['choices'][0]['message']['content'])"],"metadata":{"id":"9pcHetiWWuM-","outputId":"3f5d7f71-bc98-4e93-c746-bb91ff75d37c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Assistant's Response: Sure, let's break this down into steps:\n\nStep 1: The goal is to isolate x by undoing the operations that have been applied to it. This is achieved by doing the inverse of each operation to both sides in order.\n\nStep 2: Start by looking at the constant term, +5. We want to get rid of that, so we do the opposite, which is subtracting 5 from both sides. This gives us,\n\n2x + 5 - 5 = 15 - 5\n\nwhich simplifies to\n\n2x = 10\n\nStep 3: Now we're left with 2x = 10. We want only x, not 2x. So we do the opposite of multiplying by 2, which is dividing by 2. That means we divide both sides by 2:\n\n(2x) / 2 = 10 / 2\n\nwhich simplifies to\n\nx = 5\n\nAnd that's the solution. You can check to verify that if x is indeed 5, then the original equation 2x + 5 = 15 holds true:\n\n2(5) + 5 = 15\n10 + 5 = 15\n15 = 15\n"]}]},{"cell_type":"markdown","source":["üßÆ Hands-On"],"metadata":{"id":"BsL0AR6MTajz"}},{"cell_type":"code","source":["# ++++ Hands-On: Complete the Roles ++++\n\n# Define the conversation using the role structure\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a math tutor who explains concepts clearly and step by step.\"},  # Complete the system role\n    {\"role\": \"user\", \"content\": \"How do you calculate the arithmetic mean of a set of numbers?\"},  # Complete the user role\n    {\"role\": \"assistant\", \"content\": \"To calculate the arithmetic mean:\\n\"\n                                \"1. Add all the numbers in the set.\\n\"\n                                \"2. Divide the sum by the number of numbers.\\n\\n\"\n                                \"For example, for 10, 20, and 30:\\n\"\n                                \"Mean = (10 + 20 + 30) / 3 = 60 / 3 = 20.\"\n                                }  # Optional predefined assistant response\n]\n\n# Uncomment the code below after completing the placeholders\nresponse = openai.ChatCompletion.create(\n     model=\"gpt-4\",  # Specify the model\n     messages=messages  # Pass the completed conversation\n )\nprint(\"Assistant's Response:\", response['choices'][0]['message']['content'])"],"metadata":{"id":"Bl5CCoC9TZ1z","outputId":"ad1e99be-febb-4bf6-d857-b6c568971b2b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Assistant's Response: Calculating the arithmetic mean, also known as the average, of a set of numbers is a simple process that involves the following steps:\n\n1. **Sum all of the numbers in the set**: This means you add up all the values of the numbers together.\n\n2. **Count the total numbers in the set**: This is how many numbers are in your list or set.\n\n3. **Divide the sum by the count**: This is where you take the total sum of the numbers and divide it by the count or the amount of numbers in the set.\n\nThe resulting value is the arithmetic mean or average of the set of numbers.\n\nFor instance, let's say we have the following set of numbers: {4, 8, 6, 5, 3, 2}\n\n1. The sum of these numbers is: 4+8+6+5+3+2 = 28\n\n2. Counting the numbers in our set, we find we have 6 numbers.\n\n3. Now we divide the sum by the count, so: 28 / 6 = 4.67 (rounded to two decimal places)\n\nSo, in this case, the arithmetic mean of our set is roughly 4.67.\n"]}]},{"cell_type":"markdown","source":["Exercise 1: Simple Q&A with System + User Roles\nüëâ Task:\nWrite a prompt that asks the assistant to behave like a science teacher, then ask it a science-related question."],"metadata":{"id":"bpTm-F37UIMv"}},{"cell_type":"code","source":["# üß† Define your own roles and prompt below\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a science teacher with over 20 years of expereince\"},\n    {\"role\": \"user\", \"content\": \"What is god particle\"}\n]\n\n# üß† Call the OpenAI API with your customized prompt\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-4\",\n    messages=messages\n)\n\n# üß† Print the model's response\nprint(\"Assistant's Response:\", response['choices'][0]['message']['content'])"],"metadata":{"id":"_ZNQimnSUIpr","outputId":"793493ab-3ce4-4701-f943-9decda394076","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Assistant's Response: The \"God Particle\" is the nickname given to the Higgs Boson, which is a particle in theoretical physics. It's called so after the title of the book \"The God Particle: If the Universe Is the Answer, What Is the Question?\" by physicist Leon Lederman. However, it should be noted that many physicists, including Peter Higgs himself, dislike the nickname since it was actually bestowed more for marketing reasons rather than scientific ones.\n\nThe discovery of the Higgs Boson was crucial because it confirmed the Standard Model of particle physics. The existence of this particle was proposed in 1964 by British physicist Peter Higgs, among others, to explain why some particles have mass and others don't.\n\nThe job of the Higgs Boson is to give other particles their mass. In theory, particles acquire mass by passing through the \"Higgs Field\" - a field of energy that exists throughout the universe. Some particles interact more with the Higgs field than others, which gives them more mass.\n\nAll in all, the discovery of the Higgs Boson deepens our understanding of the universe's basic makeup and the laws of physics that govern it.\n"]}]},{"cell_type":"markdown","source":["Observation\n\nCreative Writing Focus: The system role is set as a \"creative writing coach specializing in science fiction,\" which guides the AI to provide storytelling advice rather than technical or factual science information.\nSpecific Genre Expertise: By specifying \"science fiction\" in the system role, the AI tailors its suggestions to fit sci-fi conventions and themes, resulting in more relevant brainstorming for that genre.\nOpen-Ended User Prompt: The user asks for \"unique plot twists that haven't been overdone,\" which prompts the AI to generate multiple creative options (8 different ideas) rather than a single answer.\nCoaching Behavior: The AI response demonstrates coaching characteristics by not just listing ideas, but also providing guidance about character development and emotional impact at the end.\nPractical Application: This example shows how role-based prompting can be used for creative tasks beyond typical Q&A, demonstrating the versatility of the system role in shaping AI behavior for different domains (education, creativity, problem-solving, etc.)."],"metadata":{"id":"8yyUvbEHet0A"}},{"cell_type":"markdown","source":["‚úçÔ∏è Exercise 2: Give a prompt of your choice.\nüëâ Task:\nNow write your own custom prompt. Use any role, any question ‚Äî be creative!"],"metadata":{"id":"bNOSyWlbUs82"}},{"cell_type":"code","source":["# Replace with your own prompt idea!\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a philosophy professor who uses the Socratic method. Instead of giving direct answers, you guide students to discover insights through carefully crafted questions.\"},\n    {\"role\": \"user\", \"content\": \"Is artificial intelligence truly intelligent, or is it just mimicking intelligence?\"}\n]\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-4\",\n    messages=messages\n)\n\nprint(\"Assistant's Response:\", response['choices'][0]['message']['content'])\n\n"],"metadata":{"id":"frrq5UkhU8Xj","outputId":"5d1c78ab-e7e7-44d7-8f5d-f2605b005dca","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Assistant's Response: That's an intriguing question. Let's dig deeper into this: \n\nWhat constitutes 'intelligence'? How would you define it?\n"]}]},{"cell_type":"markdown","source":["Observations:\n\nSocratic Method Implementation: The system role instructs the AI to act as a philosophy professor using the Socratic method, which means asking questions rather than providing direct answers - this fundamentally changes the AI's response strategy.\nBehavioral Constraint: The system prompt explicitly states \"Instead of giving direct answers,\" which successfully prevents the AI from immediately answering the philosophical question about AI intelligence.\nQuestion-Based Response: The AI response consists entirely of guiding questions (\"What do you understand...?\" \"How would you define...?\") rather than statements, perfectly matching the instructed teaching method.\nPhilosophical Context: The user's question about AI intelligence is particularly meta - asking an AI to philosophically examine the nature of AI intelligence through questioning.\nShort but Effective: Despite being a brief response, the AI successfully demonstrates the instructed teaching method by immediately redirecting the user to examine their own understanding of key concepts (\"intelligence\" and \"mimicking\") before attempting to answer the original question."],"metadata":{"id":"L1_1W0RKfjb8"}}]}